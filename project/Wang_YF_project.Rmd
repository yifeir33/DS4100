---
title: "Project"
author: "Yifei"
date: "2018/11/30"
output: html_document
---

```{r}
pldata <- read.csv("EPL_Set.csv", header = TRUE)
library(dplyr)
#list of all the teams with sorted in alphabetical order
allteam <- unique(pldata$HomeTeam) %>%
  sort
```

```{r}
#fixing the data, from 1993-1994 season to 1994-1995 doesnt have haltime result, fixing it by using 0 replace NA
#get trainset
pldata$HTHG[which(is.na(pldata$HTHG))] <- as.integer((pldata$FTHG)/2)
pldata$HTAG[which(is.na(pldata$HTAG))] <- as.integer((pldata$FTAG)/2)
pldata$HTR[which((pldata$HTR)=="")] <- pldata$FTR

```

```{r}
#total goals scored in each match
#analyzing if EPL is a popular spectator sport year by year(more goals ocurred in each match since 1993)
#this step add a column which outputs the total goal scored in each match
pldata <- mutate(pldata, totalGoalInMatch = FTHG + FTAG)
#the goal difference each match
pldata <- mutate(pldata, goalDiff = abs(FTHG-FTAG))

#calculating how many outliers historically, by goal difference and total goal in each match
outlier_count <- function(i){
  sd <- sd(i)
  mean <- mean(i)
  lower <- mean-3*sd
  upper <- mean+3*sd
  k <- i[(i<lower) | (i>upper)]
  return(length(k))
}

outlier_count(pldata$totalGoalInMatch)
#this shows 83 games have a big score
outlier_count(pldata$goalDiff)
#this shows 186 games have a big difference of final score
```
```{r}
#a new table with total goals, home goals, away goals in each season
library(ggplot2)
seasondb <- pldata %>%
  group_by(Season) %>%
  summarise(totalGoalInMatch = sum(FTHG+FTAG))

#histogram of the table
hist_season_goal <- ggplot(seasondb, aes(x=Season,y=totalGoalInMatch))+geom_point()

seasondb
hist_season_goal
```

```{r}
#Historical home team goal vs away team goal
home_goal <- sum(pldata$FTHG)
away_goal <- sum(pldata$FTAG)
home_goal # 14727
away_goal # 10838
```
```{r}
#historical standing
#standing calculating home team
home_standing <- pldata %>%
  group_by(HomeTeam) %>%
  summarise(P = length(FTR), 
            points = sum((FTHG>FTAG) * 3 +(FTHG == FTAG)*1),
            GS =sum(FTHG),
            GC =sum(FTAG)) %>%
  ungroup()
#standing calculating away team
away_standing <- pldata %>%
  group_by(AwayTeam) %>%
  summarise(P= length(FTR),
            points = sum((FTAG>FTHG) * 3 +(FTHG == FTAG)*1),
            GS =sum(FTAG),
            GC =sum(FTHG)) %>%
  ungroup()

home_standing
away_standing

```

```{r}
#add them together into a data frame
hist_standing <- data.frame(Team = allteam, 
                            points =home_standing$points +away_standing$points,
                            GD =(home_standing$GS + away_standing$GS) - (home_standing$GC + away_standing$GC),
                            TGS = (home_standing$GS + away_standing$GS)/(home_standing$P + away_standing$P),
                           TGC = (home_standing$GC + away_standing$GC)/(home_standing$P + away_standing$P), stringsAsFactors = FALSE)
hist_standing <- hist_standing[order(hist_standing$points, decreasing = TRUE),]
hist_standing$Rank <-NA 
order.points <- order(hist_standing$points, hist_standing$Team, decreasing = TRUE)
hist_standing$Rank[order.points] <- 1:nrow(hist_standing)
hist_standing

#It shows the historical performance of all the teams top four teams are Manchester United, Arsenal, Chelsea, and Liverpool.
#GD is the goal difference, TGS estimate the average number of goals they scored in each match, TGC is the average number of goals being scored in each match. We can use TGS and TGC for team performance estimation.
#It seems like Man United is the best team in past 15 years, Arsenal is the second.
```
```{r}
hist_Team_points <- ggplot(hist_standing, aes(x=Team,y=points))+geom_point()
hist_Team_points 
#this graph shows each team with how many points they have got in history by using diagram.
```

```{r}
#testing the correlation of average being scored in each match, and scored others, using pearson and spearman.
SPcor_sc <-cor(hist_standing$TGS, hist_standing$TGC, method = "spearman")
PMcor_sc <-cor(hist_standing$TGS, hist_standing$TGC, method = "pearson")

SPcor_sc
PMcor_sc
# The pearson Moment correlation coefficients for calories is -0.6133 and the spearman Rank correlation coefficients is -0.59063. Both correlation shows there is a weak negative correlation. Pearson correlation shows that it is in between no linear correlation and a negative linear correlation. Spearman correlation is similar to Pearson correlation. -0.5906 tells us that it is a weak corelation to the monotonic relationship.
```

```{r}
#put the updated database in SQL and right some queries to retrive data
library(RSQLite)

library(RODBC)
write.csv(pldata, file = "EPL_Set_Update.csv")
#import the physical csv file into my SQLite
DB <-dbConnect(SQLite(),dbname = "EPLdata.db")
#query 1: a list of game results on a specific date (4/4/2015)

dbFetch(dbSendQuery(DB, "select
esp.HomeTeam, esp.AwayTeam, esp.FTR
from
EPL_Set_Update esp
where
esp.Date ='4/4/2015'"))

#historical record of two teams such as Arsenal and Manchester United 

dbFetch(dbSendQuery(DB, "select
esp.HomeTeam, esp.AwayTeam, esp.FTR, esp.Season, esp.FTHG, esp.FTAG
from
EPL_Set_Update esp
where
esp.HomeTeam = 'Arsenal' and esp.AwayTeam = 'Man United'

union

select
esp.HomeTeam, esp.AwayTeam, esp.FTR, esp.Season, esp.FTHG, esp.FTAG
from
EPL_Set_Update esp
where
esp.HomeTeam = 'Man United' and esp.AwayTeam = 'Arsenal'"))



```
```{r}
#disconnect
dbDisconnect(DB)

```



```{r}
#knn, linear regression making predictions based on more variables
#I researched two datasets with the betting rates of each betting company to make the predictions. One is from current season(2018-2019), one is from previous season(2017-2018).
db2018.19 <- read.csv("2018-2019.csv", header = TRUE)
db2017.18 <- read.csv("2017-2018.csv", header = TRUE)

#since 2018 19 season doesnot have data for variable LBH, LBD, LBA, which are the betting rate from 
# LBH = Ladbrokes home win odds
# LBD = Ladbrokes draw odds
# LBA = Ladbrokes away win odds

#first use knn
#normalize use z-score standarization
znormalize <- function(x) {
  return ((x - mean(x)) / sd(x))
}
relative.rate <- db2017.18[24:38]
#not using the betting rates of Ladbrokes betting rates because we
#dont have them in 2018-2019 season
relative.rate$LBH <- NULL
relative.rate$LBD <- NULL
relative.rate$LBA <- NULL
#the predicting variables starting on column
znor1718 <- as.data.frame(lapply(relative.rate, znormalize))
summary(znor1718)
```

```{r}
#change the structure of the FTR into integer instead of A, D, H,
#using dummy variables: H ->2, D ->1, A->0
total1718 <- cbind(znor1718, db2017.18[7])
total1718$dumR <- NA
total1718$dumR[which((total1718$FTR)=="H")] <- 2
total1718$dumR[which((total1718$FTR)=="D")] <- 1
total1718$dumR[which((total1718$FTR)=="A")] <- 0
total1718$FTR <- NULL
summary(total1718)
```

```{r}
#create train set and test set for 17-18
rown1718 <- nrow(db2017.18)
testsetindex <- sample(1:rown1718, rown1718*0.5, replace = FALSE)
test_set <- total1718[testsetindex,]
train_set <-total1718[-testsetindex,]
train_set_label <- total1718[-testsetindex, 13]
test_set_label <- total1718[testsetindex, 13]

summary(test_set)

```

```{r}
#use knn to predic
library(class)

pred1718.knn <- knn(train = train_set, test = test_set ,cl = train_set_label, k =10)

pred1718.knn
```

```{r}
#now we get the model, lets try to predict the result of one of the match in this year with the model trained by 2017-2018 season betting data.

game1.mu.vs.lc <- data.frame(1.57,3.9,7.5,1.53,4,7.5,1.58,3.93,7.5,1.57,3.8,6,2)
pred.game1 <- knn(train = train_set, test = game1.mu.vs.lc ,cl = train_set_label, k =10)
pred.game1
#we guessed the first game between Manchester United vs Leicester is Home team win, which is MU win.
```
```{r}
library(MLmetrics)
Accuracy(test_set$dumR, pred1718.knn)
#accuracy is around 90%, compare to the results in the past
```

```{r}
#confusion matrix of the knn model
ConfusionMatrix(test_set$dumR, pred1718.knn)
```

```{r}
#use linear regression model to test
pred1718.lm <- lm(formula = dumR ~ B365H + B365D + B365A +BWH + BWD + BWA + IWH + IWD + IWA + PSH +PSD + PSA, data = train_set)
pred1718.lm
summary(pred1718.lm)
```


```{r}
#predicting using the linear regression model
lm.result <- predict.lm(pred1718.lm, test_set, type = "response")
lm.result[which(lm.result<0.5)] <- 0
lm.result[which(lm.result>=0.5&lm.result<1.5)] <- 1
lm.result[which(lm.result>1.5)] <- 2
lm.result
```

```{r}
#accuracy for linear regression model
Accuracy(lm.result, test_set$dumR)
#linear model is not very accurate for this case.
```

```{r}
#Confusion Matrix
ConfusionMatrix(lm.result, test_set$dumR)
```

```{r}
#the reason why linear regression model isn't fit is because regression models are used to predict continuous data. However, knn doesn't need source to be continuous. And is why we see the results of predictions kind squeeze in 1, which is draw. 
```

```{r}
#Now I want to use my more accurate model, knn model to predict this season results, to check the accuracy.
#input this season betting rate, test result then compare to the fact
znor1819 <- as.data.frame(lapply(db2018.19[24:35], znormalize))
summary(znor1819)
```
```{r}
#fixing the data has same column name as season 2017-2018
total1819 <- cbind(znor1819, db2018.19[7])
total1819$dumR <- NA
total1819$dumR[which((total1819$FTR)=="H")] <- 2
total1819$dumR[which((total1819$FTR)=="D")] <- 1
total1819$dumR[which((total1819$FTR)=="A")] <- 0
total1819$FTR <- NULL
summary(total1819)
```
```{r}
#using the same train set and knn method on this season's betting rate to test results
pred1819.knn <- knn(train = train_set, test = total1819 ,cl = train_set_label, k =10)
pred1819.knn
```

```{r}
Accuracy(total1819$dumR, pred1819.knn)
#my first accuracy is more than 96%
```

```{r}
#confusion matrix
ConfusionMatrix(total1819$dumR, pred1819.knn)
```




